{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deprl\n",
    "import gym\n",
    "import sconegym\n",
    "import yaml\n",
    "import torch \n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path  = []\n",
    "dir_path.append(r\"C:\\Users\\PC\\Documents\\SCONE\\results\")\n",
    "dir_path.append(r\"C:\\Users\\na062\\Documents\\SCONE\\results\")\n",
    "if os.path.exists(dir_path[0]) or os.path.isdir(dir_path[0]):\n",
    "    dir_path = dir_path[0]\n",
    "elif os.path.exists(dir_path[1]) or os.path.isdir(dir_path[1]):\n",
    "    dir_path = dir_path[1]\n",
    "\n",
    "else:\n",
    "    dir_path = input(\"경로 입력\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 1622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'config\\\\scone_walk_h1622.yaml','r') as y:\n",
    "    config = yaml.safe_load(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config['tonic']['name'] = 'h1622_v1_lua_50_bal'\n",
    "config['tonic']['name'] = \"temp_0115\"\n",
    "config['tonic']['environment'] = \"deprl.environments.Gym('sconewalk_h1622-v1')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[33mWarning: Logging new keys ['train/energy_buffer/avg_relabel_action_cost', 'critic/loss', 'critic/q', 'actor/policy_mean_loss', 'actor/policy_std_loss', 'actor/kl_mean_loss', 'actor/kl_std_loss', 'actor/alpha_mean_loss', 'actor/alpha_std_loss', 'actor/temperature_loss', 'actor/temperature', 'actor/alpha_mean', 'actor/alpha_std', 'actor/penalty_temperature']\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -406.99836654663085\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 2, Duration: 1분 42초\n",
      "End Time: 2024-01-15 16:21:07\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -384.4598721504211\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 3, Duration: 1분 42초\n",
      "End Time: 2024-01-15 16:22:50\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -308.5237600803375\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 4, Duration: 1분 43초\n",
      "End Time: 2024-01-15 16:24:33\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -318.82938661575315\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 5, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:26:18\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -326.6970688343048\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 6, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:28:03\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -344.09499926567076\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 7, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:29:48\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -270.6634980678558\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 8, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:31:32\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -265.60201745033265\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 9, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:33:17\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -288.26962399482727\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 10, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:35:02\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -281.27268943786623\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 11, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:36:47\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -301.7070529460907\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 12, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:38:31\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -329.2919832706451\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 13, Duration: 1분 45초\n",
      "End Time: 2024-01-15 16:40:17\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -289.6372314929962\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 14, Duration: 1분 46초\n",
      "End Time: 2024-01-15 16:42:04\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -275.0805531978607\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 15, Duration: 1분 46초\n",
      "End Time: 2024-01-15 16:43:50\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -275.44534068107606\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 16, Duration: 1분 46초\n",
      "End Time: 2024-01-15 16:45:37\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -292.86229701042174\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 17, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:47:21\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -270.83470940589905\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 18, Duration: 1분 39초\n",
      "End Time: 2024-01-15 16:49:01\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -306.0684576034546\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 19, Duration: 1분 46초\n",
      "End Time: 2024-01-15 16:50:47\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -257.59712743759155\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 20, Duration: 1분 45초\n",
      "End Time: 2024-01-15 16:52:33\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -296.1040152072907\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 21, Duration: 1분 40초\n",
      "End Time: 2024-01-15 16:54:13\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -277.4620430469513\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 22, Duration: 1분 40초\n",
      "End Time: 2024-01-15 16:55:53\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -272.54350595474244\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 23, Duration: 1분 44초\n",
      "End Time: 2024-01-15 16:57:38\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -296.6284530878067\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 24, Duration: 1분 46초\n",
      "End Time: 2024-01-15 16:59:24\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -259.92396693229676\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 25, Duration: 1분 43초\n",
      "End Time: 2024-01-15 17:01:07\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -274.59177713394166\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 26, Duration: 1분 40초\n",
      "End Time: 2024-01-15 17:02:48\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -255.93495116233825\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 27, Duration: 1분 44초\n",
      "End Time: 2024-01-15 17:04:32\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -263.5807647228241\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 28, Duration: 1분 39초\n",
      "End Time: 2024-01-15 17:06:12\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -287.7002998352051\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 29, Duration: 1분 40초\n",
      "End Time: 2024-01-15 17:07:52\n",
      "--------------------\n",
      "\u001b[1m\u001b[32mCUDA detected, storing default tensors on it.\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mFound earlier run, continuing training.\u001b[0m\n",
      "\u001b[1m\u001b[32m테스트 결과 평균 reward: -261.5478947162628\u001b[0m\n",
      "\u001b[1m\u001b[32mSaved\u001b[0m\n",
      "--------------------\n",
      "Iteration 30, Duration: 1분 39초\n",
      "End Time: 2024-01-15 17:09:32\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from deprl import main\n",
    "import time\n",
    "for i in range(1,30):\n",
    "    # Set the custom trainer with increasing steps for each iteration\n",
    "    config['tonic']['trainer'] = f'deprl.custom_trainer.Trainer(steps=int(2e5)*{i+1}, epoch_steps=int(2e5), save_steps=int(2e5))'\n",
    "    \n",
    "    # Capture the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Start the training process\n",
    "    main.main(config)\n",
    "    \n",
    "    # Capture the end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate and print the duration\n",
    "    duration = end_time - start_time\n",
    "    minutes, seconds = divmod(duration, 60)\n",
    "    \n",
    "    print(\"-\" * 20)    \n",
    "    print(f\"Iteration {i+1}, Duration: {int(minutes)}분 {int(seconds)}초\")\n",
    "    print(f\"End Time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.join(dir_path,config['tonic']['name'])\n",
    "names = os.listdir(path)[0]\n",
    "path = os.path.join(path,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32mLoading\u001b[0m\n",
      "Episode 0 ending; steps=93; reward=6568.202;                 com=[ 1.264790 0.635384 -0.129344 ]\n",
      "Episode 1 ending; steps=88; reward=6933.065;                 com=[ 1.376284 0.609492 -0.031971 ]\n",
      "Episode 2 ending; steps=87; reward=6958.431;                 com=[ 1.326771 0.633686 0.259756 ]\n",
      "Episode 3 ending; steps=69; reward=4470.115;                 com=[ 0.912048 0.650032 0.179794 ]\n",
      "Episode 4 ending; steps=82; reward=6277.102;                 com=[ 1.277941 0.634415 0.332600 ]\n",
      "Episode 5 ending; steps=99; reward=7808.711;                 com=[ 1.694008 0.628146 0.154833 ]\n",
      "Episode 6 ending; steps=100; reward=7892.845;                 com=[ 1.690117 0.649946 0.347537 ]\n",
      "Episode 7 ending; steps=76; reward=4537.282;                 com=[ 1.067325 0.646648 -0.274340 ]\n",
      "Episode 8 ending; steps=88; reward=6161.589;                 com=[ 1.324898 0.649205 -0.406598 ]\n",
      "Episode 9 ending; steps=77; reward=6096.806;                 com=[ 1.212275 0.616736 -0.261412 ]\n"
     ]
    }
   ],
   "source": [
    "env = eval(config['tonic']['environment'])\n",
    "policy = deprl.utils.load(os.path.join(path,'checkpoints'),env)\n",
    "env.seed(0)\n",
    "for ep in range(10):\n",
    "    ep_steps = 0\n",
    "    ep_tot_reward = 0\n",
    "    state = env.reset()\n",
    "    if ep % 1 == 0:\n",
    "        env.store_next_episode()  # Store results of every Nth episode\n",
    "\n",
    "    while True:\n",
    "        # samples random action\n",
    "        action = policy(state)\n",
    "        # applies action and advances environment by one step\n",
    "        state, reward, done, info = env.step(action)\n",
    "        ep_steps += 1\n",
    "        ep_tot_reward += reward\n",
    "\n",
    "        # check if done\n",
    "        if done or (ep_steps >= 1000):\n",
    "            print(\n",
    "                f\"Episode {ep} ending; steps={ep_steps}; reward={ep_tot_reward:0.3f}; \\\n",
    "                com={env.model.com_pos()}\"\n",
    "            )\n",
    "            env.write_now()\n",
    "            env.reset()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mLoading experiment from C:\\\\Users\\\\na062\\\\Documents\\\\SCONE\\\\results\\sconewalk_h1622_v1\\231228.094659.H1622v2k\\checkpoints\u001b[0m\n",
      "\u001b[1m\u001b[32mStochastic Switch-DEP. Paper version.\u001b[0m\n",
      "\u001b[1m\u001b[32m\n",
      "Loading weights from C:\\\\Users\\\\na062\\\\Documents\\\\SCONE\\\\results\\sconewalk_h1622_v1\\231228.094659.H1622v2k\\checkpoints\\step_5000000.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = eval(config['tonic']['environment'])\n",
    "policy = deprl.utils.load(os.path.join(path,'checkpoints'),env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_scone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
